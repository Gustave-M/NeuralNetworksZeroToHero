{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b936d12e",
   "metadata": {},
   "source": [
    "Sur chatGPT, char by char et pas des tokens ici\n",
    "\n",
    "Lire : Attention is all you need\n",
    "\n",
    "Faire les token, stoi, itos, encode, decode, \n",
    "\n",
    "adam optimizer marche mieux ici ? A comprendre ...\n",
    "\n",
    "Self-attention, juste la moyenne ça suffit ? c'est faible je toruve ...\n",
    "\n",
    "Reprendre à 58min, trick multiplication de matrice\n",
    "\n",
    "Le principe des head, des liaisons entre elle, key-query c'est à revoir ...\n",
    "\n",
    "Pause à 1h15\n",
    "\n",
    "1h38, idée du dropout sympa mais mieux de faire comme deepseek ? avec un choix non aléatoir ?\n",
    "Des tokens spéciaux pour encode/décode (exemple de la traduction avec < START> et < END>)\n",
    "\n",
    "Pre-training stage (apprendre à parler) and fine-tuning stage (apprendre à répondre)\n",
    "\n",
    "Résumé de gpt-2:\n",
    "Input : Text\n",
    "Output : Text\n",
    "1 : Text\n",
    "2 : Text -> embedingTable -> tokens\n",
    "\n",
    "\n",
    "\n",
    "X : Tokens -> embedingTable -> Text\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
